import gradio as gr
import google.generativeai as genai
import os
import fitz  
from dotenv import load_dotenv
from pathlib import Path

load_dotenv()

try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")
    genai.configure(api_key=api_key)
except Exception as e:
    print(f"API YapÄ±landÄ±rma HatasÄ±: {e}")
   
    api_error = str(e)


model = genai.GenerativeModel('gemini-2.0-flash-lite')

def process_uploaded_file(file):
    """
    KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi dosyayÄ± iÅŸler.
    Dosya PDF ise metnini Ã§Ä±karÄ±r, TXT ise iÃ§eriÄŸini okur.
    """
    if file is None:
        return None, "LÃ¼tfen bir dosya yÃ¼kleyin."

    file_path = file.name
    file_extension = Path(file_path).suffix.lower()
    
    content = ""
    try:
        if file_extension == '.pdf':
            with fitz.open(file_path) as doc:
                for page in doc:
                    content += page.get_text()
        elif file_extension == '.txt':
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        else:
            return None, "Desteklenmeyen dosya formatÄ±. LÃ¼tfen .pdf veya .txt uzantÄ±lÄ± bir dosya yÃ¼kleyin."
        
        if not content.strip():
             return None, "Dosya boÅŸ veya metin iÃ§eriÄŸi okunamadÄ±."

        return content, f"âœ… **{Path(file_path).name}** baÅŸarÄ±yla iÅŸlendi. ArtÄ±k sorularÄ±nÄ±zÄ± sorabilirsiniz."
    except Exception as e:
        return None, f"Dosya iÅŸlenirken bir hata oluÅŸtu: {e}"

def generate_chat_response(message, history, document_context):
    """
    KullanÄ±cÄ±nÄ±n sorusuna ve yÃ¼klenen dokÃ¼manÄ±n iÃ§eriÄŸine gÃ¶re cevap Ã¼retir.
    """
    if not document_context:
        return "LÃ¼tfen Ã¶nce bir SSS dokÃ¼manÄ± (.txt veya .pdf) yÃ¼kleyin."

    prompt_template = f"""
    Sen, yalnÄ±zca sana aÅŸaÄŸÄ±da saÄŸlanan 'DOKÃœMAN' iÃ§eriÄŸine dayanarak sorularÄ± yanÄ±tlayan bir SSS (SÄ±kÃ§a Sorulan Sorular) asistanÄ±sÄ±n.
    
    GÃ–REVÄ°N:
    1. KullanÄ±cÄ±nÄ±n sorusunu dikkatlice oku.
    2. CevabÄ± SADECE ve SADECE aÅŸaÄŸÄ±daki 'DOKÃœMAN' iÃ§inde ara.
    3. EÄŸer cevap dokÃ¼manda mevcutsa, cevabÄ± net ve anlaÅŸÄ±lÄ±r bir ÅŸekilde ifade et.
    4. EÄŸer cevap dokÃ¼manda kesinlikle bulunmuyorsa, "Bu bilgi saÄŸlanan dokÃ¼manda mevcut deÄŸil." veya benzeri bir ifade kullan.
    5. Kendi genel bilgini KESÄ°NLÄ°KLE kullanma. Sadece dokÃ¼mandaki bilgilere baÄŸlÄ± kal.

    DOKÃœMAN:
    ---
    {document_context}
    ---

    SORU:
    {message}

    CEVAP:
    """

    try:
       
        response = model.generate_content(prompt_template)
        return response.text
    except Exception as e:
        return f"Modelden cevap alÄ±nÄ±rken bir hata oluÅŸtu: {e}"


with gr.Blocks(theme=gr.themes.Soft(), title="Dinamik SSS Chatbot") as demo:
    
    document_context_state = gr.State(None)

    gr.Markdown("# ğŸ“„ Dinamik SSS Chatbot ")
    gr.Markdown(
        "Herhangi bir ÅŸirket veya konu iÃ§in SSS (.txt veya .pdf) dosyasÄ±nÄ± yÃ¼kleyin ve anÄ±nda o konuya Ã¶zel bir chatbot ile konuÅŸmaya baÅŸlayÄ±n."
    )
    
    if 'api_error' in locals():
         gr.Markdown(f"<h3 style='color:red;'>API YapÄ±landÄ±rma HatasÄ±: {api_error}</h3>")

    with gr.Row():
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("### 1. AdÄ±m: Dosya YÃ¼kleyin")
            file_uploader = gr.File(
                label="SSS DosyasÄ±nÄ± YÃ¼kle (.pdf, .txt)",
                file_types=['.pdf', '.txt']
            )
            upload_status = gr.Markdown("Dosya bekleniyor...")
        
        with gr.Column(scale=2):
            gr.Markdown("### 2. AdÄ±m: Soru Sorun")
            chatbot = gr.Chatbot(label="Sohbet", bubble_full_width=False, height=500)
            msg_textbox = gr.Textbox(label="Sorunuzu buraya yazÄ±n...", placeholder="Ã–rn: Ä°ade politikasÄ± nedir?")
            
        
            clear_button = gr.ClearButton([msg_textbox, chatbot], value="Sohbeti Temizle")

    file_uploader.upload(
        fn=process_uploaded_file,
        inputs=[file_uploader],
        outputs=[document_context_state, upload_status]
    )

    
    def user_interaction(message, history, context):
        history.append([message, None])
        return "", history, context

    def bot_response(history, context):
        user_message = history[-1][0]
        bot_message = generate_chat_response(user_message, history, context)
        history[-1][1] = bot_message
        return history

    msg_textbox.submit(
        fn=user_interaction,
        inputs=[msg_textbox, chatbot, document_context_state],
        outputs=[msg_textbox, chatbot, document_context_state]
    ).then(
        fn=bot_response,
        inputs=[chatbot, document_context_state],
        outputs=[chatbot]
    )


if __name__ == "__main__":
    demo.launch(debug=True) 