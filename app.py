import gradio as gr
import google.generativeai as genai
import os
import fitz  # PyMuPDF
import docx  # python-docx
from PIL import Image # Pillow
from dotenv import load_dotenv
from pathlib import Path

# --- Configuration and Setup ---
load_dotenv()

try:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEY bulunamadÄ±. LÃ¼tfen .env dosyasÄ±nÄ± kontrol edin.")
    genai.configure(api_key=api_key)
except Exception as e:
    print(f"API YapÄ±landÄ±rma HatasÄ±: {e}")
    api_error = str(e)

# IMPORTANT: We are updating the model to one that supports multimodal (text + image) input.
# 'gemini-1.5-flash-latest' is perfect for this.
model = genai.GenerativeModel('gemini-2.5-pro')

# --- File Processing Logic ---
def process_uploaded_file(file):
    """
    KullanÄ±cÄ±nÄ±n yÃ¼klediÄŸi dosyayÄ± iÅŸler.
    - PDF, DOCX, TXT: Metin iÃ§eriÄŸini Ã§Ä±karÄ±r.
    - Image: GÃ¶rÃ¼ntÃ¼ nesnesini dÃ¶ndÃ¼rÃ¼r.
    """
    if file is None:
        return None, "LÃ¼tfen bir dosya yÃ¼kleyin."

    # Gradio'nun oluÅŸturduÄŸu geÃ§ici dosyanÄ±n yolunu alÄ±yoruz.
    # Bu yÃ¶ntem, 'NamedString' hatasÄ±nÄ± Ã¶nler ve en gÃ¼venilir yoldur.
    file_path = file.name
    file_extension = Path(file_path).suffix.lower()
    
    try:
        content = None
        if file_extension == '.pdf':
            text_content = ""
            # DÃœZELTME BURADA: DosyayÄ± doÄŸrudan 'file_path' kullanarak aÃ§Ä±yoruz.
            with fitz.open(file_path) as doc:
                for page in doc:
                    text_content += page.get_text()
            content = text_content
            
        elif file_extension == '.txt':
            # .txt dosyalarÄ± iÃ§in de dosya yolunu kullanmak tutarlÄ±dÄ±r.
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
        elif file_extension == '.docx':
            # .docx dosyalarÄ± iÃ§in de dosya yolu kullanÄ±lÄ±r.
            doc = docx.Document(file_path)
            full_text = []
            for para in doc.paragraphs:
                full_text.append(para.text)
            content = '\n'.join(full_text)
            
        elif file_extension in ['.png', '.jpg', '.jpeg', '.webp']:
            # Resimler iÃ§in de dosya yolu kullanÄ±lÄ±r.
            content = Image.open(file_path)
            
        else:
            return None, "Desteklenmeyen format. LÃ¼tfen .pdf, .txt, .docx, .png, .jpg uzantÄ±lÄ± dosya yÃ¼kleyin."
        
        # Metin iÃ§eriÄŸinin boÅŸ olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        if isinstance(content, str) and not content.strip():
            return None, "Dosya boÅŸ veya metin iÃ§eriÄŸi okunamadÄ±."
        
        # Ä°Ã§eriÄŸin baÅŸarÄ±yla iÅŸlendiÄŸinden emin ol
        if content is None:
             return None, "Dosya iÅŸlenemedi."

        return content, f"âœ… **{Path(file_path).name}** baÅŸarÄ±yla iÅŸlendi. ArtÄ±k sorularÄ±nÄ±zÄ± sorabilirsiniz."
    
    except Exception as e:
        return None, f"Dosya iÅŸlenirken bir hata oluÅŸtu: {e}"
  

# --- Chat Response Generation ---
def generate_chat_response(message, history, document_context):
    """
    KullanÄ±cÄ±nÄ±n sorusuna ve yÃ¼klenen dokÃ¼manÄ±n (metin VEYA resim) iÃ§eriÄŸine gÃ¶re cevap Ã¼retir.
    """
    if not document_context:
        return "LÃ¼tfen Ã¶nce bir dokÃ¼man (.txt, .pdf, .docx, .png, .jpg) yÃ¼kleyin."

    try:
        # Case 1: The context is TEXT (from PDF, DOCX, TXT)
        if isinstance(document_context, str):
            prompt = f"""
            Sen, yalnÄ±zca sana aÅŸaÄŸÄ±da saÄŸlanan 'DOKÃœMAN' iÃ§eriÄŸine dayanarak sorularÄ± yanÄ±tlayan bir SSS (SÄ±kÃ§a Sorulan Sorular) asistanÄ±sÄ±n.
            
            GÃ–REVÄ°N:
            1. KullanÄ±cÄ±nÄ±n sorusunu dikkatlice oku.
            2. CevabÄ± SADECE ve SADECE aÅŸaÄŸÄ±daki 'DOKÃœMAN' iÃ§inde ara.
            3. EÄŸer cevap dokÃ¼manda mevcutsa, cevabÄ± net ve anlaÅŸÄ±lÄ±r bir ÅŸekilde ifade et.
            4. EÄŸer cevap dokÃ¼manda kesinlikle bulunmuyorsa, "SorularÄ±nÄ±z iÃ§in canlÄ± desteÄŸe yÃ¶nlendiriliyorsunuz" veya benzeri bir ifade kullan.
            5. Kendi genel bilgini KESÄ°NLÄ°KLE kullanma. Sadece dokÃ¼mandaki bilgilere baÄŸlÄ± kal.

            DOKÃœMAN:
            ---
            {document_context}
            ---

            SORU: {message}
            CEVAP:
            """
            # Generate content from text-only prompt
            response = model.generate_content(prompt)
        
        # Case 2: The context is an IMAGE
        elif isinstance(document_context, Image.Image):
            prompt = f"""
            Sen, yalnÄ±zca sana saÄŸlanan 'GÃ–RÃœNTÃœ'yÃ¼ analiz eden bir gÃ¶rsel asistansÄ±n.
            GÃ¶revin, kullanÄ±cÄ±nÄ±n sorduÄŸu soruyu SADECE bu gÃ¶rÃ¼ntÃ¼ye bakarak cevaplamaktÄ±r.
            GÃ¶rÃ¼ntÃ¼nÃ¼n dÄ±ÅŸÄ±ndan herhangi bir bilgi kullanma.
            
            SORU: {message}
            CEVAP:
            """
            # For multimodal input, pass a list containing the text prompt and the image
            response = model.generate_content([prompt, document_context])
        
        else:
            return "Ä°ÅŸlenemeyen bir dokÃ¼man formatÄ± ile karÅŸÄ±laÅŸÄ±ldÄ±."

        return response.text
    except Exception as e:
        return f"Modelden cevap alÄ±nÄ±rken bir hata oluÅŸtu: {e}"


# --- Gradio UI ---
with gr.Blocks(theme=gr.themes.Soft(), title="Dinamik SSS Chatbot") as demo:
    
    document_context_state = gr.State(None)

    gr.Markdown("# ğŸ“„ GeliÅŸmiÅŸ Dinamik Chatbot ")
    gr.Markdown(
        "Herhangi bir ÅŸirket veya konu iÃ§in dokÃ¼man (.txt, .pdf, .docx) veya gÃ¶rsel (.png, .jpg) yÃ¼kleyin ve anÄ±nda o konuya Ã¶zel bir chatbot ile konuÅŸmaya baÅŸlayÄ±n."
    )
    
    if 'api_error' in locals():
         gr.Markdown(f"<h3 style='color:red;'>API YapÄ±landÄ±rma HatasÄ±: {api_error}</h3>")

    with gr.Row():
        with gr.Column(scale=1, min_width=300):
            gr.Markdown("### 1. AdÄ±m: Dosya YÃ¼kleyin")
            file_uploader = gr.File(
                label="DokÃ¼man veya GÃ¶rsel YÃ¼kle",
                file_types=['.pdf', '.txt', '.docx', '.png', '.jpg', '.jpeg'] # Updated file types
            )
            upload_status = gr.Markdown("Dosya bekleniyor...")
        
        with gr.Column(scale=2):
            gr.Markdown("### 2. AdÄ±m: Soru Sorun")
            chatbot = gr.Chatbot(label="Sohbet", bubble_full_width=False, height=500)
            msg_textbox = gr.Textbox(label="Sorunuzu buraya yazÄ±n...", placeholder="Ã–rn: Ä°ade politikasÄ± nedir? / Bu resimde ne gÃ¶rÃ¼yorsun?")
            clear_button = gr.ClearButton([msg_textbox, chatbot], value="Sohbeti Temizle")

    # --- Event Handlers ---
    file_uploader.upload(
        fn=process_uploaded_file,
        inputs=[file_uploader],
        outputs=[document_context_state, upload_status]
    )

    def user_interaction(message, history):
        # We don't need to pass the context here, it's handled by the `bot_response` function
        history.append([message, None])
        return "", history

    def bot_response(history, context):
        user_message = history[-1][0]
        bot_message = generate_chat_response(user_message, history, context)
        history[-1][1] = bot_message
        return history

    # Chain of events for chat submission
    msg_textbox.submit(
        fn=user_interaction,
        inputs=[msg_textbox, chatbot],
        outputs=[msg_textbox, chatbot]
    ).then(
        fn=bot_response,
        inputs=[chatbot, document_context_state],
        outputs=[chatbot]
    )


if __name__ == "__main__":
    demo.launch(debug=True)